{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Quickstrart](https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html)\n",
    "\n",
    "\n",
    "1. [데이터 작업](#1-working-with-data)\n",
    "2. [모델 만들기](#2-creating-models)\n",
    "3. [모델 매개변수 최적화 하기](#3-optimizing-the-model-parameters)\n",
    "4. [모델 저장 및 불러오기](#4-saving-and-loading-models)\n",
    "5. [모델 사용하기](#5-predict-with-models)\n",
    "\n",
    "## 1. Working with Data \n",
    "\n",
    "#### 데이터 작업을 위한 기본 요소\n",
    "- torch.utils.data.Dataset에는 샘플과 정답(label)을 저장\n",
    "- torch.utils.data.DataLoader는 Dataset을 순회가능한 객체(iterable)로 감쌈\n",
    "\n",
    "torchvision.datasets에는 CIFAR, COCO 등 다양한 실제 vision 데이터에 대한 dataset을 포함하고 있음. 이 튜토리얼에서는 FashionMNIST를 사용. 모든 torchvision dataset은 샘플과 정답을 각각 변경하기 위한 transform과 target_transform 두 인자를 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doeun/anaconda3/envs/HF/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset을 DataLoader의 인자로 전달\n",
    "- 데이터셋을 iterable로 감쌈\n",
    "- 자동화된 batch, sampling shuffle 및 multiprocess dataloading 지원\n",
    "\n",
    "batch size = 64 : dataloader 객채의 각 요소는 64개의 feature과 정답(label)을 묶음(batch)로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dataset : 60000\n",
      "len of dataloader : 938\n",
      "Shape of X [N, C, H, W] : torch.Size([64, 1, 28, 28]), torch.float32\n",
      "Shape of y : torch.Size([64]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 \n",
    "\n",
    "print(f'len of dataset : {len(training_data)}')\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size= batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size= batch_size)\n",
    "\n",
    "print(f'len of dataloader : {len(train_dataloader)}')\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f'Shape of X [N, C, H, W] : {X.shape}, {X.dtype}')\n",
    "    print(f'Shape of y : {y.shape}, {y.dtype}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Models\n",
    "\n",
    "신경망 모델\n",
    "- nn.Module을 상속받는 class를 생성하여 정의\n",
    "- \\_\\_init\\_\\_ 에서 신경망의 layer 정의\n",
    "- forward에서 신경망에 데이터를 어떻게 전달할지 지정\n",
    "- 가능한 경우 GPU나 MPS로 신경망을 이동시켜 연산을 가속\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f'using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10) \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizing the Model Parameters \n",
    "\n",
    "모델 학습에는 loss function과 optimizer가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 학습 단계에서 모델은 \n",
    "- batch로 묶여서 제공되는 학습 데이터셋에 대한 예측을 수행\n",
    "- 예측 오류를 역전파 하여 모델의 매개변수를 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for n, (X,y) in enumerate(dataloader) :\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        #예측 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        #역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if n % 250 == 0 :\n",
    "            loss, current = loss.item(), (n+1) * len(X)\n",
    "            print(f'loss : {loss:>7f}, [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 학습하고 있는지 확인하기 위해 테스트 데이터셋으로 모델의 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error : \\n Accuracy :{(100*correct):>0.1f}%, Avg loss : {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 단계는 여러번의 반복 단계(epochs)를 거쳐서 수행\n",
    "- 각 epoch에서는 모델이 더 나은 예측을 하기 위해 매개변수를 학습\n",
    "- 각 epoch마다 모델의 accuracy와 loss를 출력\n",
    "- epoch 마다 정확도가 증가하고 손실이 감소하는 것을 보려고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------\n",
      "loss : 2.293193, [   64/60000]\n",
      "loss : 2.257958, [16064/60000]\n",
      "loss : 2.219961, [32064/60000]\n",
      "loss : 2.182379, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :46.1%, Avg loss : 2.162863\n",
      "\n",
      "Epoch 2\n",
      "-------------------------\n",
      "loss : 2.166061, [   64/60000]\n",
      "loss : 2.119100, [16064/60000]\n",
      "loss : 2.018646, [32064/60000]\n",
      "loss : 1.947069, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :61.9%, Avg loss : 1.904841\n",
      "\n",
      "Epoch 3\n",
      "-------------------------\n",
      "loss : 1.932667, [   64/60000]\n",
      "loss : 1.863440, [16064/60000]\n",
      "loss : 1.677570, [32064/60000]\n",
      "loss : 1.558992, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :60.0%, Avg loss : 1.540212\n",
      "\n",
      "Epoch 4\n",
      "-------------------------\n",
      "loss : 1.605775, [   64/60000]\n",
      "loss : 1.553874, [16064/60000]\n",
      "loss : 1.367319, [32064/60000]\n",
      "loss : 1.227922, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :62.7%, Avg loss : 1.270327\n",
      "\n",
      "Epoch 5\n",
      "-------------------------\n",
      "loss : 1.349178, [   64/60000]\n",
      "loss : 1.324568, [16064/60000]\n",
      "loss : 1.162399, [32064/60000]\n",
      "loss : 1.010567, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :64.6%, Avg loss : 1.100227\n",
      "\n",
      "Epoch 6\n",
      "-------------------------\n",
      "loss : 1.175609, [   64/60000]\n",
      "loss : 1.165987, [16064/60000]\n",
      "loss : 1.023092, [32064/60000]\n",
      "loss : 0.869766, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :65.9%, Avg loss : 0.989455\n",
      "\n",
      "Epoch 7\n",
      "-------------------------\n",
      "loss : 1.053797, [   64/60000]\n",
      "loss : 1.054913, [16064/60000]\n",
      "loss : 0.924583, [32064/60000]\n",
      "loss : 0.777114, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :67.2%, Avg loss : 0.914051\n",
      "\n",
      "Epoch 8\n",
      "-------------------------\n",
      "loss : 0.963856, [   64/60000]\n",
      "loss : 0.976938, [16064/60000]\n",
      "loss : 0.852472, [32064/60000]\n",
      "loss : 0.713699, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :68.3%, Avg loss : 0.860084\n",
      "\n",
      "Epoch 9\n",
      "-------------------------\n",
      "loss : 0.894288, [   64/60000]\n",
      "loss : 0.921248, [16064/60000]\n",
      "loss : 0.798537, [32064/60000]\n",
      "loss : 0.668035, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :69.4%, Avg loss : 0.819413\n",
      "\n",
      "Epoch 10\n",
      "-------------------------\n",
      "loss : 0.838469, [   64/60000]\n",
      "loss : 0.880607, [16064/60000]\n",
      "loss : 0.757435, [32064/60000]\n",
      "loss : 0.633529, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :70.6%, Avg loss : 0.787302\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn) \n",
    "\n",
    "print(\"Done!\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving and Loading Models \n",
    "\n",
    "### 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path, dir_name, model_name = os.getcwd(),\"model\", \"fashion.pt\"\n",
    "model_path = os.path.join(path,dir_name)\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)\n",
    "model_path = os.path.join(model_path,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장하는 일반적인 방법은, (모델의 매개변수들을 포함하여) 내부 상태 사전(internal state dictionary)를 직렬화(serialize)하는 것\n",
    "\n",
    "저장 torch.save(object,path)\n",
    "- model : 전체 모델 저장, *.pt\n",
    "- model.state_dict() : 모델 객체의 state_dict 저장, *.pt\n",
    "- {'model':model.state_dict(), 'optimizer':optimizer.state_dict()} : 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar 값도 포함하여 저장, *.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pytorch model state to /home/doeun/code/AI/pytorch_tutorial/model/fashion.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(),model_path)\n",
    "print(f'saved pytorch model state to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기\n",
    "\n",
    "모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predict with Models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted : Ankle boot, actual : Ankle boot\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'predicted : {predicted}, actual : {actual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
