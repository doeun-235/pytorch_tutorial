{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Quickstrart](https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html)\n",
    "\n",
    "\n",
    "1. [데이터 작업](#1-데이터-작업)\n",
    "2. [모델 만들기](#2-모델-만들기)\n",
    "3. [블라]()\n",
    "4. [블라]()\n",
    "5. [블라]()\n",
    "6. [블라]()\n",
    "\n",
    "## 1. 데이터 작업\n",
    "\n",
    "#### 데이터 작업을 위한 기본 요소\n",
    "- torch.utils.data.Dataset에는 샘플과 정답(label)을 저장\n",
    "- torch.utils.data.DataLoader는 Dataset을 순회가능한 객체(iterable)로 감쌈\n",
    "\n",
    "torchvision.datasets에는 CIFAR, COCO 등 다양한 실제 vision 데이터에 대한 dataset을 포함하고 있음. 이 튜토리얼에서는 FashionMNIST를 사용. 모든 torchvision dataset은 샘플과 정답을 각각 변경하기 위한 transform과 target_transform 두 인자를 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset을 DataLoader의 인자로 전달\n",
    "- 데이터셋을 iterable로 감쌈\n",
    "- 자동화된 batch, sampling shuffle 및 multiprocess dataloading 지원\n",
    "\n",
    "batch size = 64 : dataloader 객채의 각 요소는 64개의 feature과 정답(label)을 묶음(batch)로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dataset : 60000\n",
      "len of dataloader : 938\n",
      "Shape of X [N, C, H, W] : torch.Size([64, 1, 28, 28]), torch.float32\n",
      "Shape of y : torch.Size([64]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 \n",
    "\n",
    "print(f'len of dataset : {len(training_data)}')\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size= batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size= batch_size)\n",
    "\n",
    "print(f'len of dataloader : {len(train_dataloader)}')\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f'Shape of X [N, C, H, W] : {X.shape}, {X.dtype}')\n",
    "    print(f'Shape of y : {y.shape}, {y.dtype}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 만들기\n",
    "\n",
    "신경망 모델\n",
    "- nn.Module을 상속받는 class를 생성하여 정의\n",
    "- \\_\\_init\\_\\_ 에서 신경망의 layer 정의\n",
    "- forward에서 신경망에 데이터를 어떻게 전달할지 지정\n",
    "- 가능한 경우 GPU나 MPS로 신경망을 이동시켜 연산을 가속\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f'using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10) \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 매개변수 최적화하기\n",
    "\n",
    "모델 학습에는 loss function과 optimizer가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 학습 단계에서 모델은 \n",
    "- batch로 묶여서 제공되는 학습 데이터셋에 대한 예측을 수행\n",
    "- 예측 오류를 역전파 하여 모델의 매개변수를 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for n, (X,y) in enumerate(dataloader) :\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        #예측 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        #역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if n % 250 == 0 :\n",
    "            loss, current = loss.item(), (n+1) * len(X)\n",
    "            print(f'loss : {loss:>7f}, [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 학습하고 있는지 확인하기 위해 테스트 데이터셋으로 모델의 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error : \\n Accuracy :{(100*correct):>0.1f}%, Avg loss : {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 단계는 여러번의 반복 단계(epochs)를 거쳐서 수행\n",
    "- 각 epoch에서는 모델이 더 나은 예측을 하기 위해 매개변수를 학습\n",
    "- 각 epoch마다 모델의 accuracy와 loss를 출력\n",
    "- epoch 마다 정확도가 증가하고 손실이 감소하는 것을 보려고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------\n",
      "loss : 2.293429, [   64/60000]\n",
      "loss : 2.259256, [16064/60000]\n",
      "loss : 2.216110, [32064/60000]\n",
      "loss : 2.182154, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :37.7%, Avg loss : 2.154753\n",
      "\n",
      "Epoch 2\n",
      "-------------------------\n",
      "loss : 2.164095, [   64/60000]\n",
      "loss : 2.107197, [16064/60000]\n",
      "loss : 2.006806, [32064/60000]\n",
      "loss : 1.927693, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :56.8%, Avg loss : 1.887109\n",
      "\n",
      "Epoch 3\n",
      "-------------------------\n",
      "loss : 1.926699, [   64/60000]\n",
      "loss : 1.831523, [16064/60000]\n",
      "loss : 1.662831, [32064/60000]\n",
      "loss : 1.518369, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :61.5%, Avg loss : 1.515395\n",
      "\n",
      "Epoch 4\n",
      "-------------------------\n",
      "loss : 1.591271, [   64/60000]\n",
      "loss : 1.504569, [16064/60000]\n",
      "loss : 1.355398, [32064/60000]\n",
      "loss : 1.187382, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :63.8%, Avg loss : 1.248153\n",
      "\n",
      "Epoch 5\n",
      "-------------------------\n",
      "loss : 1.329837, [   64/60000]\n",
      "loss : 1.273671, [16064/60000]\n",
      "loss : 1.153821, [32064/60000]\n",
      "loss : 0.977512, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :65.1%, Avg loss : 1.082039\n",
      "\n",
      "Epoch 6\n",
      "-------------------------\n",
      "loss : 1.154068, [   64/60000]\n",
      "loss : 1.118450, [16064/60000]\n",
      "loss : 1.018447, [32064/60000]\n",
      "loss : 0.843267, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :66.1%, Avg loss : 0.974920\n",
      "\n",
      "Epoch 7\n",
      "-------------------------\n",
      "loss : 1.032120, [   64/60000]\n",
      "loss : 1.011781, [16064/60000]\n",
      "loss : 0.923949, [32064/60000]\n",
      "loss : 0.755176, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :67.3%, Avg loss : 0.902448\n",
      "\n",
      "Epoch 8\n",
      "-------------------------\n",
      "loss : 0.943539, [   64/60000]\n",
      "loss : 0.937976, [16064/60000]\n",
      "loss : 0.856281, [32064/60000]\n",
      "loss : 0.695237, [48064/60000]\n",
      "Test Error : \n",
      " Accuracy :68.2%, Avg loss : 0.850919\n",
      "\n",
      "Epoch 9\n",
      "-------------------------\n",
      "loss : 0.876536, [   64/60000]\n",
      "loss : 0.886362, [16064/60000]\n",
      "loss : 0.806576, [32064/60000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn) \n",
    "\n",
    "print(\"Done!\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 저장 및 불러오기\n",
    "\n",
    "### 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path, dir_name, model_name = os.getcwd(),\"model\", \"fashion.pt\"\n",
    "model_path = os.path.join(path,dir_name)\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)\n",
    "model_path = os.path.join(model_path,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장하는 일반적인 방법은, (모델의 매개변수들을 포함하여) 내부 상태 사전(internal state dictionary)를 직렬화(serialize)하는 것\n",
    "\n",
    "저장 torch.save(object,path)\n",
    "- model : 전체 모델 저장, *.pt\n",
    "- model.state_dict() : 모델 객체의 state_dict 저장, *.pt\n",
    "- {'model':model.state_dict(), 'optimizer':optimizer.state_dict()} : 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar 값도 포함하여 저장, *.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),model_path)\n",
    "print(f'saved pytorch model state to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기\n",
    "\n",
    "모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'predicted : {predicted}, actual : {actual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
